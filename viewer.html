<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8" />
    <title>BALROG Model Viewer</title>
    <meta name="description" content="BALROG: Benchmarking Agentic LLM/VLM Reasoning On Games - Model Viewer" />
    <link rel="shortcut icon" href="img/logo.png" />
    <link rel="icon" href="img/logo.png" />
    <link rel="stylesheet" href="css/normalize.css" />
    <link rel="stylesheet" href="css/fonts.css" />
    <link rel="stylesheet" href="css/styles.css" />
    <link rel="stylesheet" href="css/viewer.css" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/all.min.css"
        integrity="..." crossorigin="anonymous" />
    <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
    <!-- Include a sanitizer for security -->
    <script src="https://cdn.jsdelivr.net/npm/dompurify@2.3.6/dist/purify.min.js"></script>
</head>

<body>
    <div style="padding-bottom: 50px">
        <!-- Top Section with BALROG Title and Image -->
        <section style="background-color: var(--dark_accent_color)">
            <div class="content-wrapper title-wrapper" style="flex-direction: column">
                <div style="
                      display: flex;
                      flex-direction: row;
                      align-items: center;
                      padding-bottom: 15px;
                    ">
                    <h1 style="font-size: 60px; padding-top: 0.4em">BALROG</h1>
                    <img src="img/logo.png" style="height: 120px; padding-top: 0em; padding-left: 0.5em" />
                </div>
                <h3>Benchmarking Agentic LLM/VLM Reasoning On Games</h3>
                <!-- Model Name -->
                <h2 id="modelName" style="font-size: 40px; padding-top: 0.4em"></h2>
                <p id="modelDate">Date: </p>
                <!-- Navigation Buttons -->
                <div class="content-wrapper" style="margin-top: 2em">
                    <a href="index.html">
                        <button class="outline"
                            style="flex-direction: row; display: flex; justify-content: center; align-items: center;">
                            <img src="img/logo.png"
                                style="height: 1.8em; margin-left: -0.3em; margin-right: 0.3em; margin-bottom: 0em;" />
                            Home&nbsp;
                        </button>
                    </a>
                    <a href="https://arxiv.org/abs/2411.13543">
                        <button class="outline">
                            <i class="fa fa-paperclip"></i> Paper&nbsp;
                        </button>
                    </a>
                    <a href="https://github.com/balrog-ai/BALROG">
                        <button class="outline">
                            <i class="fab fa-github"></i> Code&nbsp;
                        </button>
                    </a>
                    <a href="submit.html">
                        <button class="outline">
                            <i class="fa fa-upload"></i> Submit&nbsp;
                        </button>
                    </a>
                    <a>
                        <button class="outline" id="toggle-style-btn">
                          <i class="fa fa-circle"> </i> Mode
                        </button>
                      </a>
            
                      <script>
                        // Define the style block as a string
                        const styleBlock = `
                          <style id="dynamic-style">
                            :root {
                              --black: #000000;
                              --green: #699f56;
                              --forest: #032f14;
                              --blue: #34566f;
                              --grey: #40434b;
                              --grey2: #d8d8d8;
                              --red: #aa4926;
                              --orange: #ff7040;
                              --lightgreen: #C2D8B9;
                              --darkorange: #d54718;
                      
                              /* BALROG */
                              /* --accent_color: rgb(200, 40, 40); */
                              --accent_color: rgb(240, 180, 95);
                              --outline_accent_color: #000;
                              /* --accent_color: #FF5733; */
                              --lighted_accent_color: rgb(90, 80, 255);
                              --dark_accent_color: transparent;
                      
                              /* Dark grey and gold */
                              /* --accent_color: rgb(242, 182, 98);
                              --dark_accent_color: rgb(41, 49, 60); */
                      
                              /* Blue and red */
                              /* --accent_color: #e91518;
                              --dark_accent_color: #0454f4; */
                              --odd_line_color: transparent;
                              --even_line_color: transparent;
                              --slate_gray: transparent;
                            }
                      
                            body {
                              background-image: url('img/background.png'); /* Replace 'img/background.jpg' with your desired image path */
                              background-size: cover; /* Ensures the image covers the entire page */
                              background-repeat: no-repeat; /* Prevents the image from repeating */
                              background-attachment: fixed; /* Keeps the image fixed during scrolling */
                            }
                      
                            body, h1, h2, h3, h4, h5, h6, p, a, .tablinks, table, th, td {
                              color: #fff !important;
                            }
            
                            ul.tab {
                              background-color: transparent !important;
                            }
            
                            ul.tab {
                              background-color: #000;
                            }
            
                            .tablinks
                            {
                              background-color: #333;
                            }
            
                            ul.tab li a:focus,.active
                            {
                              background-color: #121212;
                            }
                            
                            .number, .label-date, .text-content, .sticky-header-content {
                              color: #fff !important;
                            }
                      
                            .label-date{
                              color: #000 !important;
                              background-color: #fff !important;
                            }
                    
                            button {
                    
                            &.outline {
                              color: var(--outline_accent_color);
                            }
            
                            &.outline:hover {
                              color: #40434b;
                              border-color: #40434b;
                              transition: all 0.2s linear;
                            }
            
                          </style>
                        `;
                      
                        const toggleButton = document.getElementById('toggle-style-btn');
                      
                        // Function to apply dark mode
                        function enableDarkMode() {
                          if (!document.getElementById('dynamic-style')) {
                            document.head.insertAdjacentHTML('beforeend', styleBlock);
                          }
                          localStorage.setItem('darkMode', 'enabled');
            
                          // Update button text without removing the icon
                          toggleButton.innerHTML = '<i class="fa fa-moon">  </i> Mode';
            
                          // Change diagram to dark version
                          const diagram = document.querySelector('img[src="img/diagram.png"]');
                          if (diagram) {
                            diagram.src = 'img/diagram_dark.png';
                          }
                        }
            
                        // Function to disable dark mode
                        function disableDarkMode() {
                          const existingStyle = document.getElementById('dynamic-style');
                          if (existingStyle) {
                            existingStyle.remove();
                          }
                          localStorage.setItem('darkMode', 'disabled');
            
                          // Update button text without removing the icon
                          toggleButton.innerHTML = '<i class="fa fa-circle">  </i> Mode';
            
                          // Change diagram back to light version
                          const diagram = document.querySelector('img[src="img/diagram_dark.png"]');
                          if (diagram) {
                            diagram.src = 'img/diagram.png';
                          }
                        }
            
                      
                        // Check localStorage on page load
                        window.addEventListener('DOMContentLoaded', () => {
                        const darkMode = localStorage.getItem('darkMode');
                        if (darkMode === null || darkMode === 'enabled') {
                            enableDarkMode();
                        } else {
                            disableDarkMode();
                        }
                        });
                      
                        // Add event listener to the button
                        toggleButton.addEventListener('click', () => {
                          const darkMode = localStorage.getItem('darkMode');
                          if (darkMode === 'enabled') {
                            disableDarkMode();
                          } else {
                            enableDarkMode();
                          }
                        });
                      </script>
                </div>
            </div>
        </section>
        <!-- About Section -->
        <section class="main-container">
            <!-- Display README.md content -->
            <div class="content-wrapper">
                <div class="content-box" id="readme">
                    Loading README.md...
                </div>
            </div>
            <!-- Trajectories Section (Always displayed) -->
            <div class="content-wrapper" id="trajectoriesLinkContainer">
                <div class="content-box">
                    <h2 class="text-title">Trajectories</h2>
                    <p class="text-content" id="trajectoriesText">
                        <!-- Content will be updated via JavaScript -->
                    </p>
                </div>
            </div>
            <!-- Display Performance Data -->
            <div class="content-wrapper">
                <h3>Performance Data</h3>
                <table class="table-results" id="performanceTable">
                    <thead>
                        <tr>
                            <th>Environment</th>
                            <th>Progress (%)</th>
                            <th>Standard Error</th>
                            <th>Number of Episodes</th>
                        </tr>
                    </thead>
                    <tbody>
                        <!-- Data will be inserted here -->
                    </tbody>
                </table>
            </div>
        </section>
    </div>
    <!-- Embed the data variable -->
    <script>
        var data = {"leaderboards": [{"name": "LLM", "results": [{"average": [16.18, 1.64], "babaisai": [19.327731092436977, 3.6197542978761432, 119], "babyai": [34.0, 6.69925368977769, 50], "crafter": [27.272727272727277, 3.5790944881871867, 10], "date": "2024-11-25", "folder": "submissions/LLM/20241115_naive-Qwen2.5-72B-Instruct", "minihack": [5.0, 3.44, 40], "name": "Qwen2.5-72B-it", "nle": [0.30784538150722346, 0.2753452798438033, 5], "org_logo": "https://github.com/balrog-ai.png?size=200", "oss": true, "readme_content": "# BALROG Naive Baseline\nAs part of the original BALROG paper, we use naive zero-shot agents as the baseline approach for all the environments in BALROG.\n\nSpecifically:\n\n1. The agent is first given the rules of the games and available actions\n2. The agent is then shown the history of previous 16 observations-actions in a chat format, \n3. Finally, the agent is asked to only output a single action, with not sophisticated reasoning mechanism. \n\nTo replicate the naive baselines, use `agent.type=naive`, an example with GPT4o-mini is:\n\n```\npython eval.py \\\n  agent.type=naive \\\n  agent.max_image_history=0 \\\n  eval.num_workers=32 \\\n  client.client_name=openai \\\n  client.model_id=gpt-4o-mini-2024-07-18\n```\n\nFor more information, visit:\n\n- [Evaluation tutorial](https://github.com/balrog-ai/BALROG/blob/main/assets/evaluation.md)\n- [Paper]()\n- [BALROG](https://balrogai.com)\n\n", "site": null, "textworld": [11.176470588235295, 3.835827381829256, 30], "trajs": false, "verified": true}, {"average": [32.64471266283788, 1.9342003853175014], "babaisai": [37.5, 4.419417382415922, 120], "babyai": [68.0, 6.596969000988254, 50], "crafter": [32.72727272727273, 3.2012394293925466, 10], "date": "2024-11-11", "folder": "submissions/LLM/20241103_Claude-3.5-Sonnet", "minihack": [15.0, 5.645794895318107, 40], "name": "Claude-3.5-Sonnet-2024-10-22", "nle": [0.5821797203427749, 0.5207173719233047, 5], "org_logo": "https://github.com/balrog-ai.png?size=200", "oss": true, "readme_content": "# BALROG Naive Baseline\nAs part of the original BALROG paper, we use naive zero-shot agents as the baseline approach for all the environments in BALROG.\n\nSpecifically:\n\n1. The agent is first given the rules of the games and available actions\n2. The agent is then shown the history of previous 16 observations-actions in a chat format, \n3. Finally, the agent is asked to only output a single action, with not sophisticated reasoning mechanism. \n\nTo replicate the naive baselines, use `agent.type=naive`, an example with GPT4o-mini is:\n\n```\npython eval.py \\\n  agent.type=naive \\\n  agent.max_image_history=0 \\\n  eval.num_workers=32 \\\n  client.client_name=openai \\\n  client.model_id=gpt-4o-mini-2024-07-18\n```\n\nFor more information, visit:\n\n- [Evaluation tutorial](https://github.com/balrog-ai/BALROG/blob/main/assets/evaluation.md)\n- [Paper]()\n- [BALROG](https://balrogai.com)\n\n", "site": null, "textworld": [42.05882352941177, 5.406976071199611, 60], "trajs": true, "verified": true}, {"average": [43.55037625935449, 2.1805854808516196], "babaisai": [45.83333333333333, 4.5484785816146704, 120], "babyai": [76.0, 6.039867548216601, 50], "crafter": [57.272727272727266, 3.920701573245059, 10], "date": "2025-07-23", "folder": "submissions/LLM/20250713_naive_grok-4", "minihack": [17.5, 6.007807420348955, 40], "name": "Grok-4", "nle": [1.7550204794781488, 0.7957371700990541, 5], "org_logo": "https://github.com/balrog-ai.png?size=200", "oss": true, "readme_content": "# BALROG Grok-4\nTo replicate grok-4 with the naive agent template, use:\n\n```\nexport OPENAI_API_KEY=YOUR-XAI-API-KEY\n\npython3 -m eval \\\n  agent.type=naive \\\n  agent.max_image_history=0 \\\n  agent.max_history=16 \\\n  eval.num_workers=8 \\\n  client.client_name=xai \\\n  client.base_url=\"https://api.x.ai/v1\" \\\n  client.model_id=grok-4-latest\n```\n\nBare in mind that while this is using the naive agent, Grok4 could be reasoning before replying.\n\nFor more information, visit:\n\n- [Evaluation tutorial](https://github.com/balrog-ai/BALROG/blob/main/docs/evaluation.md)\n- [Paper](https://arxiv.org/abs/2411.13543)\n- [BALROG](https://balrogai.com)", "site": null, "textworld": [62.941176470588225, 7.868341854361763, 30], "trajs": true, "verified": true}, {"average": [14.633333333333333, 1.372992473880805], "babaisai": [12.8, 2.33, 200], "babyai": [50.0, 7.07, 50], "crafter": [20.0, 0.74, 10], "date": "2024-11-11", "folder": "submissions/LLM/20240924_naive-Gemini-1.5-Flash", "minihack": [5.0, 3.45, 40], "name": "Gemini-1.5-Flash-002", "nle": [0.0, 0.0, 5], "org_logo": "https://github.com/balrog-ai.png?size=200", "oss": true, "readme_content": "# BALROG Naive Baseline\nAs part of the original BALROG paper, we use naive zero-shot agents as the baseline approach for all the environments in BALROG.\n\nSpecifically:\n\n1. The agent is first given the rules of the games and available actions\n2. The agent is then shown the history of previous 16 observations-actions in a chat format, \n3. Finally, the agent is asked to only output a single action, with not sophisticated reasoning mechanism. \n\nTo replicate the naive baselines, use `agent.type=naive`, an example with GPT4o-mini is:\n\n```\npython eval.py \\\n  agent.type=naive \\\n  agent.max_image_history=0 \\\n  eval.num_workers=32 \\\n  client.client_name=openai \\\n  client.model_id=gpt-4o-mini-2024-07-18\n```\n\nFor more information, visit:\n\n- [Evaluation tutorial](https://github.com/balrog-ai/BALROG/blob/main/assets/evaluation.md)\n- [Paper]()\n- [BALROG](https://balrogai.com)\n\n", "site": null, "textworld": [0.0, 0.0, 60], "trajs": false, "verified": true}, {"average": [15.144385026737966, 1.5514263407931903], "babaisai": [18.333333333333332, 3.532258746447074, 120], "babyai": [36.0, 6.788225099390856, 50], "crafter": [25.454545454545453, 3.226952608963427, 10], "date": "2024-11-11", "folder": "submissions/LLM/20241101_naive-Llama-3.1-8B-Instruct", "minihack": [5.0, 3.446012188022554, 40], "name": "Llama-3.1-8B-it", "nle": [0.0, 0.0, 5], "org_logo": "https://github.com/balrog-ai.png?size=200", "oss": true, "readme_content": "# BALROG Naive Baseline\nAs part of the original BALROG paper, we use naive zero-shot agents as the baseline approach for all the environments in BALROG.\n\nSpecifically:\n\n1. The agent is first given the rules of the games and available actions\n2. The agent is then shown the history of previous 16 observations-actions in a chat format, \n3. Finally, the agent is asked to only output a single action, with not sophisticated reasoning mechanism. \n\nTo replicate the naive baselines, use `agent.type=naive`, an example with GPT4o-mini is:\n\n```\npython eval.py \\\n  agent.type=naive \\\n  agent.max_image_history=0 \\\n  eval.num_workers=32 \\\n  client.client_name=openai \\\n  client.model_id=gpt-4o-mini-2024-07-18\n```\n\nFor more information, visit:\n\n- [Evaluation tutorial](https://github.com/balrog-ai/BALROG/blob/main/assets/evaluation.md)\n- [Paper]()\n- [BALROG](https://balrogai.com)\n\n", "site": null, "textworld": [6.07843137254902, 2.409186144801279, 30], "trajs": false, "verified": true}, {"average": [7.797534165181225, 1.0978942439497628], "babaisai": [12.5, 3.0190368221228, 120], "babyai": [14.000000000000002, 4.907137658554117, 50], "crafter": [16.363636363636363, 3.0287874998104876, 10], "date": "2024-11-25", "folder": "submissions/LLM/20241115_naive-Qwen2.5-7B-it", "minihack": [0.0, 0.0, 40], "name": "Qwen-2.5-7B-it", "nle": [0.0, 0.0, 5], "org_logo": "https://github.com/balrog-ai.png?size=200", "oss": true, "readme_content": "# BALROG Naive Baseline\nAs part of the original BALROG paper, we use naive zero-shot agents as the baseline approach for all the environments in BALROG.\n\nSpecifically:\n\n1. The agent is first given the rules of the games and available actions\n2. The agent is then shown the history of previous 16 observations-actions in a chat format, \n3. Finally, the agent is asked to only output a single action, with not sophisticated reasoning mechanism. \n\nTo replicate the naive baselines, use `agent.type=naive`, an example with GPT4o-mini is:\n\n```\npython eval.py \\\n  agent.type=naive \\\n  agent.max_image_history=0 \\\n  eval.num_workers=32 \\\n  client.client_name=openai \\\n  client.model_id=gpt-4o-mini-2024-07-18\n```\n\nFor more information, visit:\n\n- [Evaluation tutorial](https://github.com/balrog-ai/BALROG/blob/main/assets/evaluation.md)\n- [Paper]()\n- [BALROG](https://balrogai.com)\n\n", "site": null, "textworld": [3.9215686274509802, 1.0125446656751418, 30], "trajs": true, "verified": true}, {"average": [19.471228579431113, 1.622490688615419], "babaisai": [40.0, 4.472135954999579, 120], "babyai": [48.0, 7.065408693062279, 50], "crafter": [14.999999999999996, 2.1368471406442104, 10], "date": "2025-01-26", "folder": "submissions/LLM/20250126_robust_cot_deepseek_R1_distill_qwen32B", "minihack": [2.5, 2.4685522072664368, 40], "name": "DeepSeek-R1-Distill-Qwen-32B", "nle": [0.7391361824690403, 0.40484156020654793, 5], "org_logo": "https://github.com/balrog-ai.png?size=200", "oss": true, "readme_content": "# BALROG DeepSeek R1 Distill Qwen 32B Chain of Thought\nTo replicate DeepSeek R1 distill Qwen 32B with the robust chain of thought agent template:\n\n```\nvllm serve deepseek-ai/DeepSeek-R1-Distill-Qwen-32B --tensor-parallel-size 2 --port 8080\n\npython3 -m eval \\\n  agent.type=robust_cot \\\n  agent.max_image_history=0 \\\n  agent.max_history=16 \\\n  eval.num_workers=4 \\\n  client.client_name=vllm \\\n  client.model_id=deepseek-ai/DeepSeek-R1-Distill-Qwen-32B\n```\n\nFor more information, visit:\n\n- [Evaluation tutorial](https://github.com/balrog-ai/BALROG/blob/main/docs/evaluation.md)\n- [Paper](https://arxiv.org/abs/2411.13543)\n- [BALROG](https://balrogai.com)", "site": null, "textworld": [10.588235294117649, 3.7450467094316306, 30], "trajs": true, "verified": true}, {"average": [11.642008318478906, 1.4408567366363194], "babaisai": [16.666666666666664, 3.4020690871988615, 120], "babyai": [32.0, 6.596969000988255, 50], "crafter": [13.636363636363635, 2.6504326794751365, 10], "date": "2025-01-13", "folder": "submissions/LLM/20250113_robust_naive_microsoft_phi-4", "minihack": [5.0, 3.4460121880225536, 40], "name": "Microsoft-Phi-4", "nle": [0.0, 0.0, 5], "org_logo": "https://github.com/balrog-ai.png?size=200", "oss": true, "readme_content": "# BALROG DeepSeek R1 Distill Qwen 32B CoT\nWe use naive zero-shot agents as the baseline for all the environments in BALROG.\n\nSpecifically:\n\n1. The agent is first given the rules of the games and available actions\n2. The agent is then shown the history of previous 16 observations-actions in a chat format, \n3. Finally, the agent is asked to only output a single action, with not sophisticated reasoning mechanism. \n\nTo replicate this robust_naive baselines, use `agent.type=robust_naive`:\n\n```\npython eval.py \\\n  agent.type=robust_naive \\\n  agent.max_image_history=0 \\\n  eval.num_workers=32 \\\n  client.client_name=claude \\\n  client.model_id=claude-3-5-haiku-20241022\n```\n\nFor more information, visit:\n\n- [Evaluation tutorial](https://github.com/balrog-ai/BALROG/blob/main/docs/evaluation.md)\n- [Paper](https://arxiv.org/abs/2411.13543)\n- [BALROG](https://balrogai.com)", "site": null, "textworld": [2.5490196078431375, 0.8628936295197067, 30], "trajs": true, "verified": true}, {"average": [29.19233586394863, 1.7683561031580985], "babaisai": [43.333333333333336, 4.5236006635160635, 120], "babyai": [76.0, 6.039867548216605, 50], "crafter": [33.63636363636363, 3.473631486280509, 10], "date": "2025-03-13", "folder": "submissions/LLM/20250313_robust_cot_Reka-Flash-3", "minihack": [10.0, 4.7434164902525655, 40], "name": "Reka-Flash-3", "nle": [0.6156907630144469, 0.33722771935058, 5], "org_logo": "https://github.com/balrog-ai.png?size=200", "oss": true, "readme_content": "# BALROG Reka-Flash-3 (21B) Chain of Thought\nTo replicate Reka-Flash-3 (21B) with the robust chain of thought agent template:\n\n```\nvllm serve RekaAI/reka-flash-3 --tensor_parallel_size 2 --port 8080\n\npython3 eval \\\n  agent.type=robust_cot \\\n  eval.num_workers=32 \\\n  client.client_name=vllm \\\n  client.model_id=RekaAI/reka-flash-3 \\\n  client.base_url=http://0.0.0.0:8080/v1\n```\n\nFor more information, visit:\n\n- [Evaluation tutorial](https://github.com/balrog-ai/BALROG/blob/main/docs/evaluation.md)\n- [Paper](https://arxiv.org/abs/2411.13543)\n- [BALROG](https://balrogai.com)", "site": null, "textworld": [11.568627450980392, 4.577357083799898, 30], "trajs": true, "verified": true}, {"average": [33.48363979929569, 2.152079488286406], "babaisai": [50.0, 4.564354645876384, 120], "babyai": [68.0, 6.596969000988254, 50], "crafter": [40.0, 4.80185914408882, 10], "date": "2025-07-22", "folder": "submissions/LLM/20250719-naive_gemini-2.5-flash", "minihack": [12.5, 5.2291251658379725, 40], "name": "Gemini-2.5-Flash", "nle": [0.7939956585192304, 0.4366159786133193, 5], "org_logo": "https://github.com/balrog-ai.png?size=200", "oss": true, "readme_content": "# BALROG Gemini-2.5-Flash\nTo replicate Gemini-2.5-Flash with the naive agent template, use:\n\n```\nexport GEMINI_API_KEY=\u003cKEY\u003e\n\npython3 -m eval \\\n  agent.type=naive \\\n  agent.max_image_history=0 \\\n  agent.max_history=16 \\\n  eval.num_workers=16 \\\n  client.client_name=gemini \\\n  client.model_id=gemini-2.5-flash\n```\n\nBare in mind that Gemini 2.5 Flash is using some reasoning internally\n\nFor more information, visit:\n\n- [Evaluation tutorial](https://github.com/balrog-ai/BALROG/blob/main/docs/evaluation.md)\n- [Paper](https://arxiv.org/abs/2411.13543)\n- [BALROG](https://balrogai.com)", "site": null, "textworld": [29.607843137254903, 7.1962832333592655, 30], "trajs": false, "verified": true}, {"average": [3.665881504116798, 0.7993593693789691], "babaisai": [7.563025210084033, 2.4238020876994986, 119], "babyai": [4.0, 2.771281292110205, 50], "crafter": [6.363636363636363, 1.7248787237282064, 10], "date": "2024-11-25", "folder": "submissions/LLM/20241115_naive-Qwen2-VL-7B-instruct", "minihack": [2.5, 2.4685522072664368, 40], "name": "Qwen2-VL-7B-it", "nle": [0.0, 0.0, 5], "org_logo": "https://github.com/balrog-ai.png?size=200", "oss": true, "readme_content": "# BALROG Naive Baseline\nAs part of the original BALROG paper, we use naive zero-shot agents as the baseline approach for all the environments in BALROG.\n\nSpecifically:\n\n1. The agent is first given the rules of the games and available actions\n2. The agent is then shown the history of previous 16 observations-actions in a chat format, \n3. Finally, the agent is asked to only output a single action, with not sophisticated reasoning mechanism. \n\nTo replicate the naive baselines, use `agent.type=naive`, an example with GPT4o-mini is:\n\n```\npython eval.py \\\n  agent.type=naive \\\n  agent.max_image_history=0 \\\n  eval.num_workers=32 \\\n  client.client_name=openai \\\n  client.model_id=gpt-4o-mini-2024-07-18\n```\n\nFor more information, visit:\n\n- [Evaluation tutorial](https://github.com/balrog-ai/BALROG/blob/main/assets/evaluation.md)\n- [Paper]()\n- [BALROG](https://balrogai.com)", "site": null, "textworld": [1.5686274509803921, 0.6159068752622091, 30], "trajs": false, "verified": true}, {"average": [29.503487428508553, 2.197008875555495], "babaisai": [33.33333333333333, 4.303314829119347, 120], "babyai": [62.0, 6.8644009206922, 50], "crafter": [25.000000000000007, 4.128614119223852, 10], "date": "2025-04-25", "folder": "submissions/LLM/20250425_naive_grok-3", "minihack": [22.5, 6.602556323122129, 40], "name": "Grok-3-beta", "nle": [1.638571629874851, 0.3780374377296403, 5], "org_logo": "https://github.com/balrog-ai.png?size=200", "oss": true, "readme_content": "# BALROG Grok-3-beta\nTo replicate grok-3-beta with the naive agent template, use:\n\n```\nexport OPENAI_API_KEY=YOUR-XAI-API-KEY\n\npython3 -m eval \\\n  agent.type=naive \\\n  agent.max_image_history=0 \\\n  agent.max_text_history=16 \\\n  eval.num_workers=16 \\\n  client.client_name=xai \\\n  client.base_url=\"https://api.x.ai/v1\" \\\n  client.model_id=grok-3-beta\n```\n\nFor more information, visit:\n\n- [Evaluation tutorial](https://github.com/balrog-ai/BALROG/blob/main/docs/evaluation.md)\n- [Paper](https://arxiv.org/abs/2411.13543)\n- [BALROG](https://balrogai.com)", "site": null, "textworld": [32.549019607843135, 6.880835167725513, 30], "trajs": true, "verified": true}, {"average": [10.133689839572192, 1.280367136777229], "babaisai": [17.5, 3.4686092313779033, 120], "babyai": [20.0, 5.656854249492381, 50], "crafter": [17.27272727272727, 2.7872199485010714, 10], "date": "2024-11-11", "folder": "submissions/LLM/20241030_naive-Llama-3.2-3B-Instruct", "minihack": [2.5, 2.4685522072664368, 40], "name": "Llama-3.2-3B-it", "nle": [0.0, 0.0, 5], "org_logo": "https://github.com/balrog-ai.png?size=200", "oss": true, "readme_content": "# BALROG Naive Baseline\nAs part of the original BALROG paper, we use naive zero-shot agents as the baseline approach for all the environments in BALROG.\n\nSpecifically:\n\n1. The agent is first given the rules of the games and available actions\n2. The agent is then shown the history of previous 16 observations-actions in a chat format, \n3. Finally, the agent is asked to only output a single action, with not sophisticated reasoning mechanism. \n\nTo replicate the naive baselines, use `agent.type=naive`, an example with GPT4o-mini is:\n\n```\npython eval.py \\\n  agent.type=naive \\\n  agent.max_image_history=0 \\\n  eval.num_workers=32 \\\n  client.client_name=openai \\\n  client.model_id=gpt-4o-mini-2024-07-18\n```\n\nFor more information, visit:\n\n- [Evaluation tutorial](https://github.com/balrog-ai/BALROG/blob/main/assets/evaluation.md)\n- [Paper]()\n- [BALROG](https://balrogai.com)\n\n", "site": null, "textworld": [3.5294117647058822, 1.0595494969495132, 30], "trajs": true, "verified": true}, {"average": [23.03203437290035, 1.6588823778056299], "babaisai": [29.166666666666668, 4.149269235080457, 120], "babyai": [66.0, 6.699253689777692, 50], "crafter": [28.636363636363633, 4.0681183336844455, 10], "date": "2024-12-09", "folder": "submissions/LLM/20241209_naive_Llama-3.3-70B-Instruct", "minihack": [5.0, 3.446012188022554, 40], "name": "Llama-3.3-70B-it", "nle": [0.36956809123452017, 0.33055174972609247, 5], "org_logo": "https://github.com/balrog-ai.png?size=200", "oss": true, "readme_content": "# BALROG Naive Baseline\nWe use naive zero-shot agents as the baseline for all the environments in BALROG.\n\nSpecifically:\n\n1. The agent is first given the rules of the games and available actions\n2. The agent is then shown the history of previous 16 observations-actions in a chat format, \n3. Finally, the agent is asked to only output a single action, with no sophisticated reasoning mechanism. \n\nTo replicate the naive baselines, use `agent.type=naive`:\n\n```\nvllm serve meta-llama/Llama-3.3-70B-Instruct --port 8080\n\npython eval.py \\\n  agent.type=naive \\\n  agent.max_image_history=0 \\\n  agent.max_history=16 \\\n  eval.num_workers=32 \\\n  client.client_name=vllm \\\n  client.model_id=meta-llama/Llama-3.3-70B-Instruct \\\n  client.base_url=http://0.0.0.0:8080/v1\n```\n\nFor more information, visit:\n\n- [Evaluation tutorial](https://github.com/balrog-ai/BALROG/blob/main/assets/evaluation.md)\n- [Paper](https://arxiv.org/abs/2411.13543)\n- [BALROG](https://balrogai.com)\n\n", "site": null, "textworld": [9.019607843137255, 2.9047857650598834, 30], "trajs": true, "verified": true}, {"average": [32.34, 1.49], "babaisai": [33.66, 3.3, 200], "babyai": [77.6, 3.73, 125], "crafter": [33.1, 2.32, 10], "date": "2024-11-11", "folder": "submissions/LLM/20240924_naive-GPT4o", "minihack": [10.0, 4.74, 40], "name": "GPT-4o-2024-05-13", "nle": [0.37, 0.37, 5], "org_logo": "https://github.com/balrog-ai.png?size=200", "oss": true, "readme_content": "# BALROG Naive Baseline\nAs part of the original BALROG paper, we use naive zero-shot agents as the baseline approach for all the environments in BALROG.\n\nSpecifically:\n\n1. The agent is first given the rules of the games and available actions\n2. The agent is then shown the history of previous 16 observations-actions in a chat format, \n3. Finally, the agent is asked to only output a single action, with not sophisticated reasoning mechanism. \n\nTo replicate the naive baselines, use `agent.type=naive`, an example with GPT4o-mini is:\n\n```\npython eval.py \\\n  agent.type=naive \\\n  agent.max_image_history=0 \\\n  eval.num_workers=32 \\\n  client.client_name=openai \\\n  client.model_id=gpt-4o-mini-2024-07-18\n```\n\nFor more information, visit:\n\n- [Evaluation tutorial](https://github.com/balrog-ai/BALROG/blob/main/assets/evaluation.md)\n- [Paper]()\n- [BALROG](https://balrogai.com)\n\n", "site": null, "textworld": [39.31, 5.24, 60], "trajs": false, "verified": true}, {"average": [21.0, 1.18], "babaisai": [32.02, 3.26, 200], "babyai": [58.4, 4.41, 125], "crafter": [30.21, 2.86, 10], "date": "2024-11-11", "folder": "submissions/LLM/20240924_naive-Gemini-1.5-Pro", "minihack": [5.0, 3.45, 40], "name": "Gemini-1.5-Pro-002", "nle": [0.37, 0.37, 5], "org_logo": "https://github.com/balrog-ai.png?size=200", "oss": true, "readme_content": "# BALROG Naive Baseline\nAs part of the original BALROG paper, we use naive zero-shot agents as the baseline approach for all the environments in BALROG.\n\nSpecifically:\n\n1. The agent is first given the rules of the games and available actions\n2. The agent is then shown the history of previous 16 observations-actions in a chat format, \n3. Finally, the agent is asked to only output a single action, with not sophisticated reasoning mechanism. \n\nTo replicate the naive baselines, use `agent.type=naive`, an example with GPT4o-mini is:\n\n```\npython eval.py \\\n  agent.type=naive \\\n  agent.max_image_history=0 \\\n  eval.num_workers=32 \\\n  client.client_name=openai \\\n  client.model_id=gpt-4o-mini-2024-07-18\n```\n\nFor more information, visit:\n\n- [Evaluation tutorial](https://github.com/balrog-ai/BALROG/blob/main/assets/evaluation.md)\n- [Paper]()\n- [BALROG](https://balrogai.com)\n\n", "site": null, "textworld": [0.0, 0.0, 60], "trajs": false, "verified": true}, {"average": [12.75, 1.56], "babaisai": [10.83, 2.84, 120], "babyai": [24.0, 6.04, 50], "crafter": [22.72, 2.73, 10], "date": "2024-11-25", "folder": "submissions/LLM/20241115_naive-Qwen2-VL-72B-Instruct", "minihack": [2.5, 2.47, 40], "name": "Qwen2-VL-72B-it", "nle": [0.0, 0.0, 5], "org_logo": "https://github.com/balrog-ai.png?size=200", "oss": true, "readme_content": "# BALROG Naive Baseline\nAs part of the original BALROG paper, we use naive zero-shot agents as the baseline approach for all the environments in BALROG.\n\nSpecifically:\n\n1. The agent is first given the rules of the games and available actions\n2. The agent is then shown the history of previous 16 observations-actions in a chat format, \n3. Finally, the agent is asked to only output a single action, with not sophisticated reasoning mechanism. \n\nTo replicate the naive baselines, use `agent.type=naive`, an example with GPT4o-mini is:\n\n```\npython eval.py \\\n  agent.type=naive \\\n  agent.max_image_history=0 \\\n  eval.num_workers=32 \\\n  client.client_name=openai \\\n  client.model_id=gpt-4o-mini-2024-07-18\n```\n\nFor more information, visit:\n\n- [Evaluation tutorial](https://github.com/balrog-ai/BALROG/blob/main/assets/evaluation.md)\n- [Paper]()\n- [BALROG](https://balrogai.com)\n\n", "site": null, "textworld": [16.47, 5.39, 30], "trajs": false, "verified": true}, {"average": [17.646375893946985, 1.4794126953475895], "babaisai": [20.833333333333336, 3.7073188375108734, 120], "babyai": [50.0, 7.0710678118654755, 50], "crafter": [27.727272727272727, 2.685282815953078, 10], "date": "2024-12-09", "folder": "submissions/LLM/20241209_naive-mistral-nemo-instruct", "minihack": [2.5, 2.4685522072664368, 40], "name": "Mistral-Nemo-it-2407", "nle": [0.30784538150722346, 0.2753452798438033, 5], "org_logo": "https://github.com/balrog-ai.png?size=200", "oss": true, "readme_content": "# BALROG Naive Baseline\nWe use naive zero-shot agents as the baseline for all the environments in BALROG.\n\nSpecifically:\n\n1. The agent is first given the rules of the games and available actions\n2. The agent is then shown the history of previous 16 observations-actions in a chat format, \n3. Finally, the agent is asked to only output a single action, with no sophisticated reasoning mechanism. \n\nTo replicate the naive baselines, use `agent.type=naive`:\n\n```\nvllm serve mistralai/Mistral-Nemo-Instruct-2407 --port 8080\n\npython eval.py \\\n  agent.type=naive \\\n  agent.max_image_history=0 \\\n  agent.max_history=16 \\\n  eval.num_workers=32 \\\n  client.client_name=vllm \\\n  client.model_id=mistralai/Mistral-Nemo-Instruct-2407 \\\n  client.base_url=http://0.0.0.0:8080/v1\n```\n\nFor more information, visit:\n\n- [Evaluation tutorial](https://github.com/balrog-ai/BALROG/blob/main/assets/evaluation.md)\n- [Paper](https://arxiv.org/abs/2411.13543)\n- [BALROG](https://balrogai.com)\n\n", "site": null, "textworld": [4.509803921568627, 1.2912425975989794, 30], "trajs": true, "verified": true}, {"average": [27.876666666666665, 1.4263453688048735], "babaisai": [40.0, 3.42, 200], "babyai": [73.2, 3.96, 125], "crafter": [31.21, 2.68, 10], "date": "2024-11-11", "folder": "submissions/LLM/20240930_naive-Llama-3.1-70B-Instruct", "minihack": [7.5, 4.16, 40], "name": "Llama-3.1-70B-it", "nle": [0.35, 0.35, 5], "org_logo": "https://github.com/balrog-ai.png?size=200", "oss": true, "readme_content": "# BALROG Naive Baseline\nAs part of the original BALROG paper, we use naive zero-shot agents as the baseline approach for all the environments in BALROG.\n\nSpecifically:\n\n1. The agent is first given the rules of the games and available actions\n2. The agent is then shown the history of previous 16 observations-actions in a chat format, \n3. Finally, the agent is asked to only output a single action, with not sophisticated reasoning mechanism. \n\nTo replicate the naive baselines, use `agent.type=naive`, an example with GPT4o-mini is:\n\n```\npython eval.py \\\n  agent.type=naive \\\n  agent.max_image_history=0 \\\n  eval.num_workers=32 \\\n  client.client_name=openai \\\n  client.model_id=gpt-4o-mini-2024-07-18\n```\n\nFor more information, visit:\n\n- [Evaluation tutorial](https://github.com/balrog-ai/BALROG/blob/main/assets/evaluation.md)\n- [Paper]()\n- [BALROG](https://balrogai.com)\n\n", "site": null, "textworld": [15.0, 4.61, 60], "trajs": false, "verified": true}, {"average": [17.36, 1.35], "babaisai": [15.6, 2.53, 200], "babyai": [50.4, 4.47, 125], "crafter": [15.9, 2.05, 10], "date": "2024-11-11", "folder": "submissions/LLM/20240924_naive-GPT4o-mini", "minihack": [10.0, 4.74, 40], "name": "GPT-4o-mini-2024-07-18", "nle": [0.0, 0.0, 5], "org_logo": "https://github.com/balrog-ai.png?size=200", "oss": true, "readme_content": "# BALROG Naive Baseline\nAs part of the original BALROG paper, we use naive zero-shot agents as the baseline approach for all the environments in BALROG.\n\nSpecifically:\n\n1. The agent is first given the rules of the games and available actions\n2. The agent is then shown the history of previous 16 observations-actions in a chat format, \n3. Finally, the agent is asked to only output a single action, with not sophisticated reasoning mechanism. \n\nTo replicate the naive baselines, use `agent.type=naive`, an example with GPT4o-mini is:\n\n```\npython eval.py \\\n  agent.type=naive \\\n  agent.max_image_history=0 \\\n  eval.num_workers=32 \\\n  client.client_name=openai \\\n  client.model_id=gpt-4o-mini-2024-07-18\n```\n\nFor more information, visit:\n\n- [Evaluation tutorial](https://github.com/balrog-ai/BALROG/blob/main/assets/evaluation.md)\n- [Paper]()\n- [BALROG](https://balrogai.com)\n\n", "site": null, "textworld": [12.25, 3.55, 60], "trajs": false, "verified": true}, {"average": [27.293333333333337, 1.4426730591355603], "babaisai": [43.9, 3.47, 200], "babyai": [72.0, 6.35, 50], "crafter": [31.68, 1.36, 10], "date": "2024-11-11", "folder": "submissions/LLM/20240930_naive-Llama-3.2-90B-Instruct", "minihack": [5.0, 3.44, 40], "name": "Llama-3.2-90B-it", "nle": [0.0, 0.0, 5], "org_logo": "https://github.com/balrog-ai.png?size=200", "oss": true, "readme_content": "# BALROG Naive Baseline\nAs part of the original BALROG paper, we use naive zero-shot agents as the baseline approach for all the environments in BALROG.\n\nSpecifically:\n\n1. The agent is first given the rules of the games and available actions\n2. The agent is then shown the history of previous 16 observations-actions in a chat format, \n3. Finally, the agent is asked to only output a single action, with not sophisticated reasoning mechanism. \n\nTo replicate the naive baselines, use `agent.type=naive`, an example with GPT4o-mini is:\n\n```\npython eval.py \\\n  agent.type=naive \\\n  agent.max_image_history=0 \\\n  eval.num_workers=32 \\\n  client.client_name=openai \\\n  client.model_id=gpt-4o-mini-2024-07-18\n```\n\nFor more information, visit:\n\n- [Evaluation tutorial](https://github.com/balrog-ai/BALROG/blob/main/assets/evaluation.md)\n- [Paper]()\n- [BALROG](https://balrogai.com)\n\n", "site": null, "textworld": [11.18, 2.98, 60], "trajs": false, "verified": true}, {"average": [19.31525904701802, 1.8294268418571227], "babaisai": [8.333333333333332, 2.5230419617479125, 120], "babyai": [52.0, 7.065408693062279, 50], "crafter": [26.36363636363636, 2.7872199485010705, 10], "date": "2024-12-11", "folder": "submissions/LLM/20241209_naive-claude-3-5-haiku", "minihack": [10.0, 4.743416490252569, 40], "name": "Claude-3.5-Haiku-2024-10-22", "nle": [1.1553688988639115, 0.423598115933611, 5], "org_logo": "https://github.com/balrog-ai.png?size=200", "oss": true, "readme_content": "# BALROG Naive Baseline\nWe use naive zero-shot agents as the baseline for all the environments in BALROG.\n\nSpecifically:\n\n1. The agent is first given the rules of the games and available actions\n2. The agent is then shown the history of previous 16 observations-actions in a chat format, \n3. Finally, the agent is asked to only output a single action, with not sophisticated reasoning mechanism. \n\nTo replicate this naive baselines, use `agent.type=naive`:\n\n```\npython eval.py \\\n  agent.type=naive \\\n  agent.max_image_history=0 \\\n  eval.num_workers=32 \\\n  client.client_name=claude \\\n  client.model_id=claude-3-5-haiku-20241022\n```\n\nFor more information, visit:\n\n- [Evaluation tutorial](https://github.com/balrog-ai/BALROG/blob/main/assets/evaluation.md)\n- [Paper](https://arxiv.org/abs/2411.13543)\n- [BALROG](https://balrogai.com)", "site": null, "textworld": [18.03921568627451, 5.809571530119767, 30], "trajs": true, "verified": true}, {"average": [16.825, 1.470721667149234], "babaisai": [15.6, 2.5, 200], "babyai": [50.0, 7.07, 50], "crafter": [26.19, 3.29, 10], "date": "2024-11-11", "folder": "submissions/LLM/20240930_naive-Llama-3.2-11B-Instruct", "minihack": [2.5, 2.47, 40], "name": "Llama-3.2-11B-it", "nle": [0.0, 0.0, 5], "org_logo": "https://github.com/balrog-ai.png?size=200", "oss": true, "readme_content": "# BALROG Naive Baseline\nAs part of the original BALROG paper, we use naive zero-shot agents as the baseline approach for all the environments in BALROG.\n\nSpecifically:\n\n1. The agent is first given the rules of the games and available actions\n2. The agent is then shown the history of previous 16 observations-actions in a chat format, \n3. Finally, the agent is asked to only output a single action, with not sophisticated reasoning mechanism. \n\nTo replicate the naive baselines, use `agent.type=naive`, an example with GPT4o-mini is:\n\n```\npython eval.py \\\n  agent.type=naive \\\n  agent.max_image_history=0 \\\n  eval.num_workers=32 \\\n  client.client_name=openai \\\n  client.model_id=gpt-4o-mini-2024-07-18\n```\n\nFor more information, visit:\n\n- [Evaluation tutorial](https://github.com/balrog-ai/BALROG/blob/main/assets/evaluation.md)\n- [Paper]()\n- [BALROG](https://balrogai.com)\n\n", "site": null, "textworld": [6.66, 2.17, 60], "trajs": false, "verified": true}, {"average": [34.89071895962323, 2.091756832019414], "babaisai": [50.83333333333333, 4.563720663701531, 120], "babyai": [74.0, 6.203224967708329, 50], "crafter": [36.36363636363637, 3.8030001206094344, 10], "date": "2025-04-10", "folder": "submissions/LLM/20240410_robust_cot_DeepSeek-R1", "minihack": [25.0, 6.846531968814576, 40], "name": "DeepSeek-R1", "nle": [1.3826381784167503, 0.507820604374415, 5], "org_logo": "https://github.com/balrog-ai.png?size=200", "oss": true, "readme_content": "# BALROG DeepSeek R1 Chain of Thought\nTo replicate DeepSeek R1 with the robust chain of thought agent template using NVIDIA NIM\n\n\nexport OPENAI_API_KEY=YOUR-NVIDIA-NIM-API-KEY\n\n```\npython3 -m eval \\\n  agent.type=robust_cot \\\n  agent.max_image_history=0 \\\n  agent.max_history=16 \\\n  eval.num_workers=4 \\\n  client.client_name=nvidia \\\n  client.model_id=deepseek-ai/DeepSeek-R1\n```\n\nFor more information, visit:\n\n- [Evaluation tutorial](https://github.com/balrog-ai/BALROG/blob/main/docs/evaluation.md)\n- [Paper](https://arxiv.org/abs/2411.13543)\n- [BALROG](https://balrogai.com)", "site": null, "textworld": [21.764705882352942, 6.0508545855042115, 30], "trajs": false, "verified": true}, {"average": [43.346016457403294, 2.3067880978013555], "babaisai": [56.666666666666664, 4.523600663516065, 120], "babyai": [80.0, 5.656854249492381, 50], "crafter": [55.00000000000001, 5.976883844936904, 10], "date": "2025-04-25", "folder": "submissions/LLM/20250425_naive_Gemini-2.5-Pro-Exp-03-25", "minihack": [17.5, 6.007807420348955, 40], "name": "Gemini-2.5-Pro-Exp-03-25", "nle": [1.6937458032433108, 0.20935132629788197, 10], "org_logo": "https://github.com/balrog-ai.png?size=200", "oss": true, "readme_content": "# BALROG Gemini-2.5-Pro-Exp\nTo replicate Gemini-2.5-Pro-Exp with the naive agent template, use:\n\n```\nexport GEMINI_API_KEY=YOUR-GEMINI-API-KEY\n\npython3 -m eval \\\n  agent.type=naive \\\n  agent.max_image_history=0 \\\n  agent.max_text_history=16 \\\n  eval.num_workers=16 \\\n  client.client_name=gemini \\\n  client.model_id=gemini-2.5-pro-preview-03-25\n```\n\nBare in mind that Gemini 2.5 Pro is using some reasoning internally\n\nFor more information, visit:\n\n- [Evaluation tutorial](https://github.com/balrog-ai/BALROG/blob/main/docs/evaluation.md)\n- [Paper](https://arxiv.org/abs/2411.13543)\n- [BALROG](https://balrogai.com)", "site": null, "textworld": [49.2156862745098, 8.200127217125015, 30], "trajs": true, "verified": true}, {"average": [6.648989898989899, 1.0422013437544229], "babaisai": [10.833333333333334, 2.837211398277984, 120], "babyai": [8.0, 3.8366652186501793, 50], "crafter": [12.727272727272727, 1.9069251784911847, 10], "date": "2024-11-11", "folder": "submissions/LLM/20241030_naive-Llama-3.2-1B-Instruct", "minihack": [5.0, 3.446012188022554, 40], "name": "Llama-3.2-1B-it", "nle": [0.0, 0.0, 5], "org_logo": "https://github.com/balrog-ai.png?size=200", "oss": true, "readme_content": "# BALROG Naive Baseline\nAs part of the original BALROG paper, we use naive zero-shot agents as the baseline approach for all the environments in BALROG.\n\nSpecifically:\n\n1. The agent is first given the rules of the games and available actions\n2. The agent is then shown the history of previous 16 observations-actions in a chat format, \n3. Finally, the agent is asked to only output a single action, with not sophisticated reasoning mechanism. \n\nTo replicate the naive baselines, use `agent.type=naive`, an example with GPT4o-mini is:\n\n```\npython eval.py \\\n  agent.type=naive \\\n  agent.max_image_history=0 \\\n  eval.num_workers=32 \\\n  client.client_name=openai \\\n  client.model_id=gpt-4o-mini-2024-07-18\n```\n\nFor more information, visit:\n\n- [Evaluation tutorial](https://github.com/balrog-ai/BALROG/blob/main/assets/evaluation.md)\n- [Paper]()\n- [BALROG](https://balrogai.com)\n\n", "site": null, "textworld": [3.3333333333333335, 0.9063547420103955, 30], "trajs": true, "verified": true}]}, {"name": "VLM", "results": [{"average": [35.47637553683924, 2.0209436790267405], "babaisai": [34.45378151260504, 4.3563101057350435, 119], "babyai": [82.0, 5.433231082882449, 50], "crafter": [37.272727272727266, 3.1360342383018796, 10], "date": "2024-11-11", "folder": "submissions/VLM/20241103_Claude-3.5-Sonnet", "minihack": [22.5, 6.602556323122129, 40], "name": "Claude-3.5-Sonnet-2024-10-22", "nle": [1.1553688988639113, 0.423598115933611, 5], "org_logo": "https://github.com/balrog-ai.png?size=200", "oss": true, "readme_content": "# BALROG Naive Baseline\nAs part of the original BALROG paper, we use naive zero-shot agents as the baseline approach for all the environments in BALROG.\n\nSpecifically:\n\n1. The agent is first given the rules of the games and available actions\n2. The agent is then shown the history of previous 16 observations-actions in a chat format, \n3. Finally, the agent is asked to only output a single action, with not sophisticated reasoning mechanism. \n\nTo replicate the naive baselines, use `agent.type=naive`, an example with GPT4o-mini is:\n\n```\npython eval.py \\\n  agent.type=naive \\\n  agent.max_image_history=0 \\\n  eval.num_workers=32 \\\n  client.client_name=openai \\\n  client.model_id=gpt-4o-mini-2024-07-18\n```\n\nFor more information, visit:\n\n- [Evaluation tutorial](https://github.com/balrog-ai/BALROG/blob/main/assets/evaluation.md)\n- [Paper]()\n- [BALROG](https://balrogai.com)\n\n", "site": null, "trajs": true, "verified": true}, {"average": [14.940000000000001, 1.3992655216219687], "babaisai": [8.3, 1.92, 200], "babyai": [43.2, 4.43, 125], "crafter": [20.7, 4.42, 10], "date": "2024-11-11", "folder": "submissions/VLM/20240924_naive-Gemini-1.5-Flash", "minihack": [2.5, 2.47, 40], "name": "Gemini-1.5-Flash-002", "nle": [0.0, 0.0, 5], "org_logo": "https://github.com/balrog-ai.png?size=200", "oss": true, "readme_content": "# BALROG Naive Baseline\nAs part of the original BALROG paper, we use naive zero-shot agents as the baseline approach for all the environments in BALROG.\n\nSpecifically:\n\n1. The agent is first given the rules of the games and available actions\n2. The agent is then shown the history of previous 16 observations-actions in a chat format, \n3. Finally, the agent is asked to only output a single action, with not sophisticated reasoning mechanism. \n\nTo replicate the naive baselines, use `agent.type=naive`, an example with GPT4o-mini is:\n\n```\npython eval.py \\\n  agent.type=naive \\\n  agent.max_image_history=0 \\\n  eval.num_workers=32 \\\n  client.client_name=openai \\\n  client.model_id=gpt-4o-mini-2024-07-18\n```\n\nFor more information, visit:\n\n- [Evaluation tutorial](https://github.com/balrog-ai/BALROG/blob/main/assets/evaluation.md)\n- [Paper]()\n- [BALROG](https://balrogai.com)\n\n", "site": null, "trajs": false, "verified": true}, {"average": [4.3799560913219935, 0.8492538039049989], "babaisai": [11.864406779661017, 2.976854968958091, 118], "babyai": [2.0, 1.9798989873223312, 50], "crafter": [5.454545454545454, 0.8624393618641033, 10], "date": "2024-11-25", "folder": "submissions/VLM/20241115_naive-Qwen2-VL-7B-instruct", "minihack": [5.0, 3.446012188022554, 40], "name": "Qwen2-VL-7B-it", "nle": [0.0, 0.0, 5], "org_logo": "https://github.com/balrog-ai.png?size=200", "oss": true, "readme_content": "# BALROG Naive Baseline\nAs part of the original BALROG paper, we use naive zero-shot agents as the baseline approach for all the environments in BALROG.\n\nSpecifically:\n\n1. The agent is first given the rules of the games and available actions\n2. The agent is then shown the history of previous 16 observations-actions in a chat format, \n3. Finally, the agent is asked to only output a single action, with not sophisticated reasoning mechanism. \n\nTo replicate the naive baselines, use `agent.type=naive`, an example with GPT4o-mini is:\n\n```\npython eval.py \\\n  agent.type=naive \\\n  agent.max_image_history=0 \\\n  eval.num_workers=32 \\\n  client.client_name=openai \\\n  client.model_id=gpt-4o-mini-2024-07-18\n```\n\nFor more information, visit:\n\n- [Evaluation tutorial](https://github.com/balrog-ai/BALROG/blob/main/assets/evaluation.md)\n- [Paper]()\n- [BALROG](https://balrogai.com)", "site": null, "textworld": [1.9607843137254901, 0.7509232217696767, 30], "trajs": false, "verified": true}, {"average": [22.560000000000002, 1.444882002102594], "babaisai": [18.62, 2.72, 200], "babyai": [62.0, 4.34, 125], "crafter": [26.81, 3.74, 10], "date": "2024-11-11", "folder": "submissions/VLM/20240930_naive-gpt-4o", "minihack": [5.0, 3.44, 40], "name": "GPT-4o-2024-05-13", "nle": [0.37, 0.37, 5], "org_logo": "https://github.com/balrog-ai.png?size=200", "oss": true, "readme_content": "# BALROG Naive Baseline\nAs part of the original BALROG paper, we use naive zero-shot agents as the baseline approach for all the environments in BALROG.\n\nSpecifically:\n\n1. The agent is first given the rules of the games and available actions\n2. The agent is then shown the history of previous 16 observations-actions in a chat format, \n3. Finally, the agent is asked to only output a single action, with not sophisticated reasoning mechanism. \n\nTo replicate the naive baselines, use `agent.type=naive`, an example with GPT4o-mini is:\n\n```\npython eval.py \\\n  agent.type=naive \\\n  agent.max_image_history=0 \\\n  eval.num_workers=32 \\\n  client.client_name=openai \\\n  client.model_id=gpt-4o-mini-2024-07-18\n```\n\nFor more information, visit:\n\n- [Evaluation tutorial](https://github.com/balrog-ai/BALROG/blob/main/assets/evaluation.md)\n- [Paper]()\n- [BALROG](https://balrogai.com)\n\n", "site": null, "trajs": false, "verified": true}, {"average": [25.7568, 1.3608593755417937], "babaisai": [31.4, 3.24, 200], "babyai": [58.4, 4.41, 125], "crafter": [33.5, 2.07, 10], "date": "2024-11-11", "folder": "submissions/VLM/20240924_naive-Gemini-1.5-Pro", "minihack": [5.0, 3.44, 40], "name": "Gemini-1.5-Pro-002", "nle": [0.484, 0.484, 5], "org_logo": "https://github.com/balrog-ai.png?size=200", "oss": true, "readme_content": "# BALROG Naive Baseline\nAs part of the original BALROG paper, we use naive zero-shot agents as the baseline approach for all the environments in BALROG.\n\nSpecifically:\n\n1. The agent is first given the rules of the games and available actions\n2. The agent is then shown the history of previous 16 observations-actions in a chat format, \n3. Finally, the agent is asked to only output a single action, with not sophisticated reasoning mechanism. \n\nTo replicate the naive baselines, use `agent.type=naive`, an example with GPT4o-mini is:\n\n```\npython eval.py \\\n  agent.type=naive \\\n  agent.max_image_history=0 \\\n  eval.num_workers=32 \\\n  client.client_name=openai \\\n  client.model_id=gpt-4o-mini-2024-07-18\n```\n\nFor more information, visit:\n\n- [Evaluation tutorial](https://github.com/balrog-ai/BALROG/blob/main/assets/evaluation.md)\n- [Paper]()\n- [BALROG](https://balrogai.com)\n\n", "site": null, "trajs": false, "verified": true}, {"average": [12.212, 1.5919912060058623], "babaisai": [5.93, 2.18, 120], "babyai": [34.0, 6.7, 50], "crafter": [18.63, 2.76, 10], "date": "2024-11-25", "folder": "submissions/VLM/20241115_naive-Qwen2-VL-72B-Instruct", "minihack": [2.5, 2.47, 40], "name": "Qwen2-VL-72B-it", "nle": [0.0, 0.0, 5], "org_logo": "https://github.com/balrog-ai.png?size=200", "oss": true, "readme_content": "# BALROG Naive Baseline\nAs part of the original BALROG paper, we use naive zero-shot agents as the baseline approach for all the environments in BALROG.\n\nSpecifically:\n\n1. The agent is first given the rules of the games and available actions\n2. The agent is then shown the history of previous 16 observations-actions in a chat format, \n3. Finally, the agent is asked to only output a single action, with not sophisticated reasoning mechanism. \n\nTo replicate the naive baselines, use `agent.type=naive`, an example with GPT4o-mini is:\n\n```\npython eval.py \\\n  agent.type=naive \\\n  agent.max_image_history=0 \\\n  eval.num_workers=32 \\\n  client.client_name=openai \\\n  client.model_id=gpt-4o-mini-2024-07-18\n```\n\nFor more information, visit:\n\n- [Evaluation tutorial](https://github.com/balrog-ai/BALROG/blob/main/assets/evaluation.md)\n- [Paper]()\n- [BALROG](https://balrogai.com)\n\n", "site": null, "trajs": false, "verified": true}, {"average": [20.988, 1.582188357939724], "babaisai": [21.9, 2.89, 200], "babyai": [66.0, 6.7, 50], "crafter": [14.54, 1.8, 10], "date": "2024-11-11", "folder": "submissions/VLM/20240930_naive-Llama-3.2-90B-Instruct", "minihack": [2.5, 2.47, 40], "name": "Llama-3.2-90B-it", "nle": [0.0, 0.0, 5], "org_logo": "https://github.com/balrog-ai.png?size=200", "oss": true, "readme_content": "# BALROG Naive Baseline\nAs part of the original BALROG paper, we use naive zero-shot agents as the baseline approach for all the environments in BALROG.\n\nSpecifically:\n\n1. The agent is first given the rules of the games and available actions\n2. The agent is then shown the history of previous 16 observations-actions in a chat format, \n3. Finally, the agent is asked to only output a single action, with not sophisticated reasoning mechanism. \n\nTo replicate the naive baselines, use `agent.type=naive`, an example with GPT4o-mini is:\n\n```\npython eval.py \\\n  agent.type=naive \\\n  agent.max_image_history=0 \\\n  eval.num_workers=32 \\\n  client.client_name=openai \\\n  client.model_id=gpt-4o-mini-2024-07-18\n```\n\nFor more information, visit:\n\n- [Evaluation tutorial](https://github.com/balrog-ai/BALROG/blob/main/assets/evaluation.md)\n- [Paper]()\n- [BALROG](https://balrogai.com)\n\n", "site": null, "trajs": false, "verified": true}, {"average": [8.434, 1.2576008905849263], "babaisai": [5.76, 1.63, 200], "babyai": [18.0, 5.43, 50], "crafter": [15.91, 1.16, 10], "date": "2024-11-11", "folder": "submissions/VLM/20240930_naive-Llama-3.2-11B-Instruct", "minihack": [2.5, 2.46, 40], "name": "Llama-3.2-11B-it", "nle": [0.0, 0.0, 5], "org_logo": "https://github.com/balrog-ai.png?size=200", "oss": true, "readme_content": "# BALROG Naive Baseline\nAs part of the original BALROG paper, we use naive zero-shot agents as the baseline approach for all the environments in BALROG.\n\nSpecifically:\n\n1. The agent is first given the rules of the games and available actions\n2. The agent is then shown the history of previous 16 observations-actions in a chat format, \n3. Finally, the agent is asked to only output a single action, with not sophisticated reasoning mechanism. \n\nTo replicate the naive baselines, use `agent.type=naive`, an example with GPT4o-mini is:\n\n```\npython eval.py \\\n  agent.type=naive \\\n  agent.max_image_history=0 \\\n  eval.num_workers=32 \\\n  client.client_name=openai \\\n  client.model_id=gpt-4o-mini-2024-07-18\n```\n\nFor more information, visit:\n\n- [Evaluation tutorial](https://github.com/balrog-ai/BALROG/blob/main/assets/evaluation.md)\n- [Paper]()\n- [BALROG](https://balrogai.com)\n\n", "site": null, "trajs": false, "verified": true}, {"average": [35.74892644718709, 2.0795418891934045], "babaisai": [53.333333333333336, 4.5542003404264815, 120], "babyai": [74.0, 6.20322496770833, 50], "crafter": [37.27272727272727, 4.626549327272535, 10], "date": "2025-04-25", "folder": "submissions/VLM/20250425_naive_Gemini-2.5-Pro-Exp-03-25", "minihack": [12.5, 5.2291251658379725, 40], "name": "Gemini-2.5-Pro-Exp-03-25", "nle": [1.638571629874851, 0.3780374377296403, 5], "org_logo": "https://github.com/balrog-ai.png?size=200", "oss": true, "readme_content": "# BALROG Gemini-2.5-Pro-Exp\nTo replicate Gemini-2.5-Pro-Exp with the naive agent template in VLM mode, use:\n\n```\nexport GEMINI_API_KEY=\u003cKEY\u003e\n\npython3 -m eval \\\n  agent.type=naive \\\n  agent.max_image_history=1 \\\n  agent.max_text_history=16 \\\n  eval.num_workers=16 \\\n  client.client_name=gemini \\\n  client.model_id=gemini-2.5-pro-preview-03-25\n```\n\nBare in mind that Gemini 2.5 Pro is using some reasoning internally\n\nFor more information, visit:\n\n- [Evaluation tutorial](https://github.com/balrog-ai/BALROG/blob/main/docs/evaluation.md)\n- [Paper](https://arxiv.org/abs/2411.13543)\n- [BALROG](https://balrogai.com)", "site": null, "trajs": true, "verified": true}, {"average": [15.3632, 1.2875014563098561], "babaisai": [16.41, 2.59, 200], "babyai": [38.0, 4.34, 125], "crafter": [19.906, 3.13, 10], "date": "2024-11-11", "folder": "submissions/VLM/20240930_naive-gpt-4o-mini", "minihack": [2.5, 2.47, 40], "name": "GPT-4o-mini-2024-07-18", "nle": [0.0, 0.0, 5], "org_logo": "https://github.com/balrog-ai.png?size=200", "oss": true, "readme_content": "# BALROG Naive Baseline\nAs part of the original BALROG paper, we use naive zero-shot agents as the baseline approach for all the environments in BALROG.\n\nSpecifically:\n\n1. The agent is first given the rules of the games and available actions\n2. The agent is then shown the history of previous 16 observations-actions in a chat format, \n3. Finally, the agent is asked to only output a single action, with not sophisticated reasoning mechanism. \n\nTo replicate the naive baselines, use `agent.type=naive`, an example with GPT4o-mini is:\n\n```\npython eval.py \\\n  agent.type=naive \\\n  agent.max_image_history=0 \\\n  eval.num_workers=32 \\\n  client.client_name=openai \\\n  client.model_id=gpt-4o-mini-2024-07-18\n```\n\nFor more information, visit:\n\n- [Evaluation tutorial](https://github.com/balrog-ai/BALROG/blob/main/assets/evaluation.md)\n- [Paper]()\n- [BALROG](https://balrogai.com)\n\n", "site": null, "trajs": false, "verified": true}]}]};
    </script>
    <script>
        // Function to read query parameters
        function getQueryParams() {
            const params = new URLSearchParams(window.location.search);
            return {
                model: params.get('model'),
                leaderboard: params.get('leaderboard')
            };
        }

        // Function to display the model data
        function displayModelData() {
            const { model, leaderboard } = getQueryParams();
            if (!model || !leaderboard) {
                document.getElementById('modelName').textContent = 'Model not specified';
                return;
            }

            const leaderboards = data.leaderboards;
            let modelData = null;

            // Find the model data
            for (const lb of leaderboards) {
                if (lb.name === leaderboard) {
                    modelData = lb.results.find(item => item.name === model);
                    break;
                }
            }

            if (!modelData) {
                document.getElementById('modelName').textContent = 'Model not found';
                return;
            }

            // Update page content
            document.getElementById('modelName').textContent = modelData.name;
            document.getElementById('modelDate').textContent = 'Date: ' + modelData.date;

            // Display performance data
            const environments = ['babyai', 'crafter', 'textworld', 'babaisai', 'minihack', 'nle'];
            const tbody = document.querySelector('#performanceTable tbody');
            tbody.innerHTML = '';

            for (const env of environments) {
                if (env in modelData) {
                    const [progress, stdError, episodes] = modelData[env];
                    const row = document.createElement('tr');
                    row.innerHTML = `
                        <td>${env.charAt(0).toUpperCase() + env.slice(1)}</td>
                        <td>${progress.toFixed(2)}</td>
                        <td>${stdError.toFixed(2)}</td>
                        <td>${episodes}</td>
                    `;
                    tbody.appendChild(row);
                }
            }

            // Add average
            if ('average' in modelData) {
                const [avgProgress, avgStdError] = modelData.average;
                const avgRow = document.createElement('tr');
                avgRow.innerHTML = `
                    <td><strong>Average</strong></td>
                    <td>${avgProgress.toFixed(2)}</td>
                    <td>${avgStdError.toFixed(2)}</td>
                    <td>-</td>
                `;
                tbody.appendChild(avgRow);
            }

            // Display README.md content
            const readmeContent = modelData.readme_content || 'README.md not provided.';
            const sanitizedContent = DOMPurify.sanitize(readmeContent);
            document.getElementById('readme').innerHTML = marked.parse(sanitizedContent);

            // Display Trajectories Information
            const trajectoriesLinkContainer = document.getElementById('trajectoriesLinkContainer');
            const trajectoriesText = document.getElementById('trajectoriesText');
            if (modelData.trajs === true) {
                // Construct the GitHub URL
                const githubUrl = 'https://github.com/balrog-ai/experiments/tree/main/' + modelData.folder;
                trajectoriesText.innerHTML = `Trajectories are available for this model. You can view them on GitHub: <a href="${githubUrl}" target="_blank">View Trajectories</a>`;
            } else {
                trajectoriesText.textContent = 'Trajectories are not available for this model.';
            }
        }

        // Call the function on page load
        displayModelData();
    </script>
</body>

</html>